{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d02737",
   "metadata": {},
   "source": [
    "# Scam Detection Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "67bb3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8e637",
   "metadata": {},
   "source": [
    "### Generating a Toy Dataset for Scams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3bb6b177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "db2b5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Define number of records\n",
    "num_records = 10000\n",
    "\n",
    "# Helper functions for generating data\n",
    "def generate_transaction_amount(is_scam):\n",
    "    if is_scam:\n",
    "        return np.round(np.random.uniform(50, 5000), 2)  # Larger amounts for scams\n",
    "    else:\n",
    "        return np.round(np.random.uniform(10, 1000), 2)  # Smaller amounts for normal transactions\n",
    "\n",
    "def generate_transaction_datetime():\n",
    "    # Simulate more transactions during weekdays and less on weekends\n",
    "    weekday_prob = 0.8\n",
    "    if random.random() < weekday_prob:\n",
    "        # Random weekday time\n",
    "        day = np.random.randint(0, 5)  # Monday to Friday\n",
    "        hour = np.random.randint(8, 18)  # Business hours\n",
    "    else:\n",
    "        # Random weekend time\n",
    "        day = np.random.randint(5, 7)  # Saturday and Sunday\n",
    "        hour = np.random.randint(8, 20)  # Wider range on weekends\n",
    "    minute = np.random.randint(0, 60)\n",
    "    second = np.random.randint(0, 60)\n",
    "    return datetime(2023, 1, 1) + timedelta(days=day, hours=hour, \n",
    "                                            minutes=minute, seconds=second)\n",
    "\n",
    "def generate_is_scam():\n",
    "    # Set a low probability (5%) for a transaction to be a scam\n",
    "    return np.random.binomial(1, 0.05, 1)[0]\n",
    "\n",
    "# Function to generate scam names based on certain patterns\n",
    "def generate_scam_name():\n",
    "    return fake.first_name() + \" \" + fake.last_name_nonbinary()\n",
    "\n",
    "# Function to generate non-scam names based on common naming conventions\n",
    "def generate_non_scam_name():\n",
    "    return fake.first_name() + \" \" + fake.last_name()\n",
    "\n",
    "# Function to generate names based on scam status\n",
    "def generate_name(is_scam):\n",
    "    if is_scam:\n",
    "        return generate_scam_name()\n",
    "    else:\n",
    "        return generate_non_scam_name()\n",
    "\n",
    "# Function to generate scam messages\n",
    "def generate_scam_message():\n",
    "    return fake.sentence(nb_words=6) + \" Urgent action required!\"\n",
    "\n",
    "# Function to generate non-scam messages\n",
    "def generate_non_scam_message():\n",
    "    return \"Thank you for your recent transaction. Your account balance is updated.\"\n",
    "\n",
    "# Function to generate messages based on scam status\n",
    "def generate_message(is_scam):\n",
    "    if is_scam:\n",
    "        return generate_scam_message()\n",
    "    else:\n",
    "        return generate_non_scam_message()\n",
    "\n",
    "# Generate data\n",
    "data = []\n",
    "for _ in range(num_records):\n",
    "    is_scam = generate_is_scam()\n",
    "    transaction_amount = generate_transaction_amount(is_scam)\n",
    "    transaction_datetime = generate_transaction_datetime()\n",
    "    recipient_name = generate_name(is_scam)\n",
    "    sender_name = generate_name(is_scam)\n",
    "    message = generate_message(is_scam)\n",
    "    data.append({\n",
    "        'transaction_amount': transaction_amount,\n",
    "        'transaction_datetime': transaction_datetime,\n",
    "        'is_scam': is_scam,\n",
    "        'recipient_name': recipient_name,\n",
    "        'sender_name': sender_name,\n",
    "        'message': message\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "48340134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy dataset saved to toy_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "toy_dataset_path = 'toy_dataset.csv'\n",
    "data.to_csv(toy_dataset_path, index=False)\n",
    "\n",
    "print(f\"Toy dataset saved to {toy_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "36ec6ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>transaction_datetime</th>\n",
       "      <th>is_scam</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>951.21</td>\n",
       "      <td>2023-01-03 15:20:38</td>\n",
       "      <td>0</td>\n",
       "      <td>Ariel Hanson</td>\n",
       "      <td>Matthew Newton</td>\n",
       "      <td>Thank you for your recent transaction. Your ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108.98</td>\n",
       "      <td>2023-01-03 15:52:35</td>\n",
       "      <td>0</td>\n",
       "      <td>Melanie Ortiz</td>\n",
       "      <td>April Collier</td>\n",
       "      <td>Thank you for your recent transaction. Your ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>654.38</td>\n",
       "      <td>2023-01-05 09:23:43</td>\n",
       "      <td>0</td>\n",
       "      <td>Whitney Duran</td>\n",
       "      <td>Samantha Gregory</td>\n",
       "      <td>Thank you for your recent transaction. Your ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.77</td>\n",
       "      <td>2023-01-04 12:32:11</td>\n",
       "      <td>0</td>\n",
       "      <td>Tina Levy</td>\n",
       "      <td>Karen Mcdonald</td>\n",
       "      <td>Thank you for your recent transaction. Your ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.00</td>\n",
       "      <td>2023-01-01 08:26:58</td>\n",
       "      <td>0</td>\n",
       "      <td>Judy Bishop</td>\n",
       "      <td>Tara Roberts</td>\n",
       "      <td>Thank you for your recent transaction. Your ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_amount transaction_datetime  is_scam recipient_name  \\\n",
       "0              951.21  2023-01-03 15:20:38        0   Ariel Hanson   \n",
       "1              108.98  2023-01-03 15:52:35        0  Melanie Ortiz   \n",
       "2              654.38  2023-01-05 09:23:43        0  Whitney Duran   \n",
       "3               10.77  2023-01-04 12:32:11        0      Tina Levy   \n",
       "4               17.00  2023-01-01 08:26:58        0    Judy Bishop   \n",
       "\n",
       "        sender_name                                            message  \n",
       "0    Matthew Newton  Thank you for your recent transaction. Your ac...  \n",
       "1     April Collier  Thank you for your recent transaction. Your ac...  \n",
       "2  Samantha Gregory  Thank you for your recent transaction. Your ac...  \n",
       "3    Karen Mcdonald  Thank you for your recent transaction. Your ac...  \n",
       "4      Tara Roberts  Thank you for your recent transaction. Your ac...  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7048f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [word for word in tokens if word.isalpha()]  # Remove non-alphabetic tokens\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the text columns\n",
    "data['message_tokens'] = data['message'].apply(preprocess_text)\n",
    "data['recipient_name_tokens'] = data['recipient_name'].apply(preprocess_text)\n",
    "data['sender_name_tokens'] = data['sender_name'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "19036807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Word2Vec model on the tokens\n",
    "all_tokens = data['message_tokens'].tolist() + data['recipient_name_tokens'].tolist() + data['sender_name_tokens'].tolist()\n",
    "word2vec_model = gensim.models.Word2Vec(all_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the embedding for a text\n",
    "def get_text_embedding(tokens, model):\n",
    "    embedding = np.mean([model.wv[word] for word in tokens if word in model.wv], axis=0)\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        return embedding\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Get embeddings for the text columns\n",
    "data['message_embedding'] = data['message_tokens'].apply(lambda x: get_text_embedding(x, word2vec_model).tolist())\n",
    "data['recipient_name_embedding'] = data['recipient_name_tokens'].apply(lambda x: get_text_embedding(x, word2vec_model).tolist())\n",
    "data['sender_name_embedding'] = data['sender_name_tokens'].apply(lambda x: get_text_embedding(x, word2vec_model).tolist())\n",
    "\n",
    "# Drop the token columns\n",
    "data = data.drop(columns=['message_tokens', 'recipient_name_tokens', 'sender_name_tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c1138bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embedding columns from lists to arrays of floats\n",
    "data['message_embedding'] = data['message_embedding'].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "data['recipient_name_embedding'] = data['recipient_name_embedding'].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "data['sender_name_embedding'] = data['sender_name_embedding'].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "\n",
    "# Expand arrays into separate columns\n",
    "message_embedding_data = pd.DataFrame(data['message_embedding'].tolist(), index=data.index).add_prefix('message_embedding_')\n",
    "recipient_name_embedding_data = pd.DataFrame(data['recipient_name_embedding'].tolist(), index=data.index).add_prefix('recipient_name_embedding_')\n",
    "sender_name_embedding_data = pd.DataFrame(data['sender_name_embedding'].tolist(), index=data.index).add_prefix('sender_name_embedding_')\n",
    "\n",
    "# Concatenate embeddings into the original dataframe\n",
    "data = pd.concat([data, message_embedding_data, recipient_name_embedding_data, sender_name_embedding_data], axis=1)\n",
    "\n",
    "# Drop the original embedding columns\n",
    "data = data.drop(columns=['message_embedding', 'recipient_name_embedding', 'sender_name_embedding'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6fe53454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 306 entries, transaction_amount to sender_name_embedding_99\n",
      "dtypes: datetime64[ns](1), float32(300), float64(1), int32(1), object(3)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "4ff6f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 302 entries, transaction_amount to sender_name_embedding_99\n",
      "dtypes: float32(300), float64(1), int32(1)\n",
      "memory usage: 11.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with object and datetime64[ns] data types\n",
    "columns_to_drop = data.select_dtypes(include=['object', 'datetime64[ns]']).columns\n",
    "\n",
    "# Drop the identified columns\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3d5d1f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1901\n",
      "           1       1.00      1.00      1.00        99\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = data.drop(columns=['is_scam'])\n",
    "y = data['is_scam']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8acb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
